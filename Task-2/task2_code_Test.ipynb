{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2_code_Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr5em3pz-5o1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive/EE698V/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX5gUW66-8ec"
      },
      "source": [
        "NUM = 10\n",
        "row_len = 513 # Number of rows: 1 + n_fft/2\n",
        "frames = 50 # frames*(min_duration*1/0.01) = columns\n",
        "outname = \"Task2.csv\" # header is off, columns are \"File\" and \"Labels\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJCN-XI3--Q0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import config, distribute\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W3ZOZQIMvOU"
      },
      "source": [
        "gpus = config.list_physical_devices('GPU');\n",
        "print(gpus)\n",
        "\n",
        "if len(gpus) == 1:\n",
        "    strategy = distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
        "else:\n",
        "    strategy = distribute.MirroredStrategy()\n",
        "\n",
        "config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9BPSYE4_AMd"
      },
      "source": [
        "def Slices(npfile):\n",
        "    X = np.load(npfile)\n",
        "\n",
        "    if X.shape[1] < frames:\n",
        "        return [np.zeros((row_len, frames))]\n",
        "\n",
        "    if X.shape[0] > row_len:\n",
        "        max_offset = X.shape[0] - row_len\n",
        "        offset = np.random.randint(max_offset)\n",
        "        X = X[offset : (row_len + offset), :]\n",
        "    else:\n",
        "        if X.shape[0] < row_len:\n",
        "            max_offset = row_len - X.shape[0]\n",
        "            offset = np.random.randint(max_offset)\n",
        "        else:\n",
        "            offset = 0\n",
        "        X = np.pad(X, ((offset, row_len - X.shape[0] - offset), (0, 0)), \"constant\")\n",
        "\n",
        "    STFTs = []\n",
        "    C = int(X.shape[1]/frames)\n",
        "    for c in range(C):\n",
        "        STFT_sample = X[:, c*frames : (c + 1)*frames]\n",
        "        STFTs.append(STFT_sample)\n",
        "\n",
        "    return STFTs\n",
        "\n",
        "def prepare_data(df, data_dir):\n",
        "    print(\"Number of test samples processed: \")\n",
        "    X = []\n",
        "    nums = []\n",
        "    for i, fname in enumerate(df[\"File\"]):\n",
        "        fpath = data_dir + \"/\" + fname + \".npy\"\n",
        "        STFTs = Slices(fpath)\n",
        "        nums.append(len(STFTs))\n",
        "        for _, stft in enumerate(STFTs):\n",
        "            stft = np.expand_dims(stft, axis = -1)\n",
        "            X.append(stft)\n",
        "\n",
        "        if(i != 0 and i%200 == 0):\n",
        "            print(i, end = \".. \")\n",
        "    print(df.shape[0], end = \".. \")\n",
        "    print(\"Done!\")\n",
        "\n",
        "    X = np.stack(X)\n",
        "    return X, nums\n",
        "\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size = (7, 3), strides = 2, activation = 'relu', input_shape = (row_len, frames, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size = (4, 2)))\n",
        "    model.add(Conv2D(64, kernel_size = (7, 3), strides = 2, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size = (4, 1)))\n",
        "    model.add(Conv2D(128, kernel_size = 3, strides = 2, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(32, activation = 'relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(n_classes, activation = 'softmax'))\n",
        "\n",
        "    model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H9RsvfRD4uf"
      },
      "source": [
        "train = pd.read_csv(\"labels_train.csv\")\n",
        "test = pd.read_csv(\"predict_test_slices.csv\", header = None)\n",
        "test.columns =[\"File\", \"Labels\"]\n",
        "sub = test\n",
        "\n",
        "LABELS = list(train['class'].unique())\n",
        "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
        "n_classes = len(train[\"class\"].unique())\n",
        "\n",
        "X_test, labels = prepare_data(test, \"test_data_slices\")\n",
        "\n",
        "normalize = np.load(\"models/normalize_slices.npy\")\n",
        "MEAN = normalize[0]\n",
        "STD = normalize[1]\n",
        "X_test = (X_test - MEAN)/STD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0UyAPPPfPB5"
      },
      "source": [
        "result = np.zeros((X_test.shape[0], n_classes))\n",
        "\n",
        "with strategy.scope():\n",
        "    model = build_model()\n",
        "\n",
        "for num in range(NUM):\n",
        "    model.load_weights(\"models/best_slices_%d.h5\"%(num + 1))\n",
        "    predictions = model.predict(X_test, batch_size = 32, verbose = 0)\n",
        "    \n",
        "    for i in range(result.shape[0]):\n",
        "        result[i, predictions.argmax(axis = 1)[i]] = result[i, predictions.argmax(axis = 1)[i]] + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8veErQGDYUpX"
      },
      "source": [
        "false_labels = []\n",
        "threshhold = 5\n",
        "for i in range(result.shape[0]):\n",
        "    row = result[i]\n",
        "    not_false = True\n",
        "    for j in range(len(row)):\n",
        "        if (row[j] > threshhold):\n",
        "            not_false = False  \n",
        "    if not_false:\n",
        "        false_labels.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klweNdvPOoCd"
      },
      "source": [
        "result = np.array(LABELS)[np.argmax(result, axis = 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Coymd0fZjn8"
      },
      "source": [
        "for i, idx in enumerate(false_labels):\n",
        "    result[idx] = \"None\" + result[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpGqBuuANprD"
      },
      "source": [
        "idx = 0\n",
        "for i, num in enumerate(labels):\n",
        "    ans = \"\"\n",
        "    curr = \"\"\n",
        "    poss = \"\"\n",
        "    for j in range(num):\n",
        "        if (result[idx][:4] != \"None\" and result[idx] != curr):\n",
        "            ans += \"-\" + result[idx]\n",
        "            curr = result[idx]\n",
        "        if result[idx][:4] == \"None\":\n",
        "            poss = result[idx]\n",
        "        idx += 1\n",
        "\n",
        "    if len(ans):\n",
        "        ans = ans[1:]\n",
        "    else:\n",
        "        ans = poss[4:]\n",
        "    sub.iloc[i]['Labels'] = ans\n",
        "\n",
        "sub.to_csv(outname, header = None, index = False)\n",
        "print(sub)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNjPVUmParbY"
      },
      "source": [
        "# !pip install python-Levenshtein > rubish.txt\n",
        "# from Levenshtein import distance\n",
        "# import string\n",
        "\n",
        "# def editDistance(gt, est):\n",
        "#     gttokens = gt.split('-')\n",
        "#     esttokens = est.split('-')\n",
        "#     tokenset = list(set(gttokens+esttokens))\n",
        "#     token_char = {}\n",
        "#     for i in range(len(tokenset)):\n",
        "#         token_char[tokenset[i]] = string.ascii_uppercase[i]\n",
        "\n",
        "#     gtstr = [token_char[t] for t in gttokens]\n",
        "#     gtstr = ''.join(gtstr)\n",
        "#     eststr = [token_char[t] for t in esttokens]\n",
        "#     eststr = ''.join(eststr)\n",
        "    \n",
        "#     editdist = distance(gtstr, eststr)\n",
        "#     score = 1 - editdist/len(gtstr)\n",
        "#     return editdist, score\n",
        "\n",
        "# true = pd.read_csv(\"task2_truelabels.csv\", header = None)\n",
        "\n",
        "# score = 0.0\n",
        "# for i in range(sub.shape[0]):\n",
        "#     _, ss = editDistance(true[1].tolist()[i], sub['Labels'].tolist()[i])\n",
        "#     print()\n",
        "#     score += ss\n",
        "# print(score)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}