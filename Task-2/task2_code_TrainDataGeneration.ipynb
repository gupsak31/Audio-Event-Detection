{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE698V_Task2:TrainDataGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr5em3pz-5o1",
        "outputId": "418c890d-4c32-46a3-b3ae-721af60f58a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive/EE698V/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/EE698V\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX5gUW66-8ec"
      },
      "source": [
        "NUM_DATA = 5  # number of training samples\n",
        "min_duration = 0.5  # in seconds\n",
        "sampling_rate = 44100\n",
        "row_len = 513 # Number of rows: 1 + n_fft/2\n",
        "frames = 50 # frames*(min_duration*1/0.01) = columns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJCN-XI3--Q0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9BPSYE4_AMd"
      },
      "source": [
        "def wav2feat(wavfile):\n",
        "    x, _ = librosa.core.load(wavfile, sr = Fs, mono = True)\n",
        "    hop = int(0.01*Fs) # 10ms\n",
        "    win = int(0.02*Fs) # 20ms\n",
        "    X = librosa.stft(x, n_fft = 1024, hop_length = hop, win_length = win, window = 'hann', center = True, pad_mode = \"reflect\")\n",
        "    X = np.abs(X)\n",
        "\n",
        "    if X.shape[1] < frames:\n",
        "        return []\n",
        "\n",
        "    if X.shape[0] > row_len:\n",
        "        max_offset = X.shape[0] - row_len\n",
        "        offset = np.random.randint(max_offset)\n",
        "        X = X[offset : (row_len + offset), :]\n",
        "    else:\n",
        "        if X.shape[0] < row_len:\n",
        "            max_offset = row_len - X.shape[0]\n",
        "            offset = np.random.randint(max_offset)\n",
        "        else:\n",
        "            offset = 0\n",
        "        X = np.pad(X, ((offset, row_len - X.shape[0] - offset), (0, 0)), \"constant\")\n",
        "\n",
        "    STFTs = []\n",
        "    C = int(X.shape[1]/frames)\n",
        "    for c in range(C):\n",
        "        STFT_sample = X[:, c*frames : (c + 1)*frames]\n",
        "        STFTs.append(STFT_sample)\n",
        "\n",
        "    return STFTs\n",
        "\n",
        "def prepare_data(df, data_dir):\n",
        "    print(\"Number of training samples processed: \")\n",
        "    X = []\n",
        "    labels = []\n",
        "    for i, fname in enumerate(df[\"slice_file_name\"]):\n",
        "        fpath = data_dir + \"/\" + fname\n",
        "        STFTs = wav2feat(fpath)\n",
        "        for _, stft in enumerate(STFTs):\n",
        "            stft = np.expand_dims(stft, axis = -1)\n",
        "            X.append(stft)\n",
        "            labels.append(train.iloc[i]['class'])\n",
        "\n",
        "        if(i != 0 and i%200 == 0):\n",
        "            print(i, end = \".. \")\n",
        "    print(df.shape[0], end = \".. \")\n",
        "    print(\"Done!\")\n",
        "\n",
        "    X = np.stack(X)\n",
        "    labels = pd.Series(labels)\n",
        "    Y = labels.apply(lambda x : label_idx[x])\n",
        "    Y = to_categorical(Y, num_classes = n_classes)\n",
        "\n",
        "    np.save(\"train_data/train_slices\", X)\n",
        "    np.save(\"train_data/slices_target\", Y)\n",
        "    return X, Y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H9RsvfRD4uf",
        "outputId": "fb926a7a-db85-4ea1-bfbe-ab029d422ad5"
      },
      "source": [
        "train = pd.read_csv(\"labels_train.csv\")\n",
        "\n",
        "LABELS = list(train['class'].unique())\n",
        "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
        "n_classes = len(train[\"class\"].unique())\n",
        "\n",
        "X, Y = prepare_data(train, \"train_data\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples processed: \n",
            "200.. 400.. 600.. 800.. 1000.. 1200.. 1400.. 1600.. 1761.. Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCfpb_SGQuDc",
        "outputId": "83e96691-24d6-4a79-c580-e1a8d486d994"
      },
      "source": [
        "print(X.shape, Y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12488, 513, 50, 1) (12488, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}